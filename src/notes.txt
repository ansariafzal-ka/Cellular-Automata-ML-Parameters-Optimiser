- For MLR Diabetes use [-1000, 1000], for MLR California use [-10, 10] because of exploading gradients, for all other models use [-1000, 1000]
- For PLR use [-1000, 1000], even when CA seems to fail for MSE because it works for MAE
- Even for Logistic Regression and Softmax Regression use [-10, 10] to avoid errors
- Investigate further for SVR and SVC



SLR - DONE - Bounds: [-1000, 1000], Alpha: 0.01
PLR - DONE - Bounds: [-1000, 1000], Alpha: 0.01
MLR (Diabetes) - DONE - Bounds: [-1000, 1000], Alpha: 0.01 

SVC (California) - DONE - Bounds: [-1000, 1000], Alpha: 0.01
SVR (Diabetes) - DONE - Bounds: [-1000, 1000], Alpha: 0.01

=======================================================================================================================
Logistic and Softmax Regression produced exponential overflow due to very large weight initialisations. 
Hence, the bounds were restricted to [-10, 10] to maintain numerical stability during the sigmoid/softmax computation.

Logistic Regression - DONE - Bounds: [-10, 10], Alpha: 0.01 -> (-1000,1000) was causing exponential overflow
Softmax Regression - DONE - Bounds: [-10, 10], Alpha: 0.01  -> (-1000,1000) was causing exponential overflow
=======================================================================================================================
The parameter bounds and learning rate were reduced to [-10, 10] and 0.0001 respectively, to prevent exploding gradients 
and ensure numerical stability during optimisation, because the California dataset has large number of records

MLR (California) - DONE - Bounds: [-10, 10], Alpha: 0.0001
SVR (California) - DONE - Bounds: [-10, 10], Alpha: 0.0001
=======================================================================================================================